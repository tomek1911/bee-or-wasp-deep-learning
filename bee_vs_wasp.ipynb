{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bee_vs_wasp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomek1911/bee-or-wasp-deep-learning/blob/master/bee_vs_wasp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "cMHQoPY4O_dS",
        "outputId": "e8bbfac9-5d09-45ca-ea66-3a22d437b627"
      },
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# import your kaggle credentials in kaggle.json file sa explained in:\n",
        "# https://www.kaggle.com/general/74235\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc2563a7-cc3e-46ee-83af-fb91943d6914\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc2563a7-cc3e-46ee-83af-fb91943d6914\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"micharosa\",\"key\":\"c34f6df8dda23f417041431ae70e46c8\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFkX76XoQiF1",
        "outputId": "997e8e39-621e-4369-daa6-4dc834c23687"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# check if kaggle API works\n",
        "! kaggle datasets list"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                    title                                                size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/covid-world-vaccination-progress                COVID-19 World Vaccination Progress                  37KB  2021-01-29 06:59:19           3576  \n",
            "jorgesandoval/wind-power-generation                    Wind Power Generation Data                          245KB  2021-01-07 18:45:08            326  \n",
            "google/android-smartphones-high-accuracy-datasets      Android smartphones high accuracy GNSS datasets       1GB  2020-12-23 01:51:11            697  \n",
            "ayushggarg/all-trumps-twitter-insults-20152021         All Trump's Twitter insults (2015-2021)             581KB  2021-01-20 16:51:05            694  \n",
            "cdminix/us-drought-meteorological-data                 US Drought & Meteorological Data                    748MB  2021-01-20 21:48:02            120  \n",
            "sevgisarac/temperature-change                          Temperature change                                  778KB  2020-12-24 20:06:36            767  \n",
            "fedesoriano/cern-electron-collision-data               CERN electron collision data                          6MB  2020-12-25 19:04:17            135  \n",
            "tapakah68/segmentation-full-body-mads-dataset          Segmentation Full Body MADS Dataset                 474MB  2021-01-20 18:43:02             45  \n",
            "utkarshxy/who-worldhealth-statistics-2020-complete     World Health Statistics 2020|Complete|Geo-Analysis    1MB  2021-01-25 06:11:19           6496  \n",
            "sakshigoyal7/credit-card-customers                     Credit Card customers                               379KB  2020-11-19 07:38:44          20980  \n",
            "gpreda/pfizer-vaccine-tweets                           Pfizer Vaccine Tweets                               787KB  2021-01-29 06:58:34           3632  \n",
            "yamaerenay/spotify-dataset-19212020-160k-tracks        Spotify Dataset 1921-2020, 160k+ Tracks              17MB  2021-01-24 23:46:53          18162  \n",
            "arashnic/covid19-case-surveillance-public-use-dataset  Covid-19 Case Surveillance Public Use Dataset        46MB  2020-12-21 02:24:21           3069  \n",
            "arashnic/hr-analytics-job-change-of-data-scientists    HR Analytics: Job Change of Data Scientists         295KB  2020-12-07 00:25:10           5273  \n",
            "google/tinyquickdraw                                   QuickDraw Sketches                                   11GB  2018-04-18 19:38:04           2785  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019  Amazon Top 50 Bestselling Books 2009 - 2019          15KB  2020-10-13 09:39:21          15416  \n",
            "datasnaek/youtube-new                                  Trending YouTube Video Statistics                   201MB  2019-06-03 00:56:47         125247  \n",
            "zynicide/wine-reviews                                  Wine Reviews                                         51MB  2017-11-27 17:08:04         126764  \n",
            "datasnaek/chess                                        Chess Game Dataset (Lichess)                          3MB  2017-09-04 03:09:09          14153  \n",
            "nasa/kepler-exoplanet-search-results                   Kepler Exoplanet Search Results                       1MB  2017-10-10 18:26:59           5871  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GPY6GAQ8bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6de0ef-c2c2-4839-9ee7-f4ec07bed1ad"
      },
      "source": [
        "! kaggle datasets download jerzydziewierz/bee-vs-wasp --unzip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading bee-vs-wasp.zip to /content\n",
            " 98% 545M/559M [00:07<00:00, 84.2MB/s]\n",
            "100% 559M/559M [00:07<00:00, 80.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTkg44dFB6a0"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "import imutils\r\n",
        "import imgaug as ia\r\n",
        "import imgaug.augmenters as iaa\r\n",
        "import imgaug.parameters as iap\r\n",
        "from math import *\r\n",
        "from PIL import Image\r\n",
        "from imgaug.augmenters import Sequential\r\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import torchvision.transforms.functional as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP99k0HnN-6L"
      },
      "source": [
        "## Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8owr7qN9lV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00bb9fa-1188-43bc-cfee-fe746f8c40ab"
      },
      "source": [
        "data = pd.read_csv(\"/content/kaggle_bee_vs_wasp/labels.csv\")\r\n",
        "for i in data.index:\r\n",
        "    data[\"path\"].iloc[i] = data[\"path\"].iloc[i].replace(\"\\\\\", \"/\")\r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(data[\"label\"])\r\n",
        "data[\"label\"] = le.transform(data[\"label\"])\r\n",
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11421 entries, 0 to 11420\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   id                   11421 non-null  int64 \n",
            " 1   path                 11421 non-null  object\n",
            " 2   is_bee               11421 non-null  int64 \n",
            " 3   is_wasp              11421 non-null  int64 \n",
            " 4   is_otherinsect       11421 non-null  int64 \n",
            " 5   is_other             11421 non-null  int64 \n",
            " 6   photo_quality        11421 non-null  int64 \n",
            " 7   is_validation        11421 non-null  int64 \n",
            " 8   is_final_validation  11421 non-null  int64 \n",
            " 9   label                11421 non-null  int64 \n",
            "dtypes: int64(9), object(1)\n",
            "memory usage: 892.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HxqqrG0TR_1"
      },
      "source": [
        "## Podział danych "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqT-eVrKTX2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b463b5-3f7b-4139-b044-cb643b548841"
      },
      "source": [
        "def split_data(dataset):\r\n",
        "    index = list()\r\n",
        "    validation = pd.DataFrame()\r\n",
        "    final_validation = pd.DataFrame()\r\n",
        "    for i in data.index:\r\n",
        "        if dataset[\"is_validation\"].iloc[i] == 1:\r\n",
        "            validation = validation.append(dataset.iloc[i])\r\n",
        "            index.append(i)\r\n",
        "        if dataset[\"is_final_validation\"].iloc[i] == 1:    \r\n",
        "            final_validation = final_validation.append(dataset.iloc[i])\r\n",
        "            index.append(i)\r\n",
        "\r\n",
        "    dataset = dataset.drop(dataset.index[index])\r\n",
        "    dataset = dataset.reset_index()\r\n",
        "    validation = validation.reset_index()\r\n",
        "    final_validation = final_validation.reset_index()\r\n",
        "    return dataset, validation, final_validation \r\n",
        "\r\n",
        "train_df, val_df, test_df = split_data(data)\r\n",
        "\r\n",
        "# sanity check\r\n",
        "print(\"Length of train dataset: \", len(train_df))\r\n",
        "print(\"Length of validation dataset: \" ,len(val_df))\r\n",
        "print(\"Length of test dataset: \", len(test_df))\r\n",
        "\r\n",
        "val_df.label = val_df.label.astype(np.int64)\r\n",
        "test_df.label = test_df.label.astype(np.int64)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train dataset:  7939\n",
            "Length of validation dataset:  1719\n",
            "Length of test dataset:  1763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDAj2Y30V40p"
      },
      "source": [
        "## Augmentacja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4iNPz59V3Wa"
      },
      "source": [
        "class Transforms():\r\n",
        "    def __init__(self, train: bool = False):\r\n",
        "      self.train = train\r\n",
        "    \r\n",
        "    def rotate(self, image, angle):\r\n",
        "      angle = random.uniform(-angle, +angle)\r\n",
        "\r\n",
        "      transformation_matrix = torch.tensor([\r\n",
        "          [+cos(radians(angle)), -sin(radians(angle))], \r\n",
        "          [+sin(radians(angle)), +cos(radians(angle))]\r\n",
        "      ])\r\n",
        "\r\n",
        "      image = imutils.rotate(np.array(image), angle)\r\n",
        "\r\n",
        "      return Image.fromarray(image)\r\n",
        "\r\n",
        "    def resize(self, image, img_size):\r\n",
        "      image = tf.resize(image, img_size)\r\n",
        "      return image\r\n",
        "\r\n",
        "    def color_jitter(self, image):\r\n",
        "      color_jitter = transforms.ColorJitter(brightness=0.3, \r\n",
        "                                            contrast=0.3,\r\n",
        "                                            saturation=0.3, \r\n",
        "                                            hue=0.1)\r\n",
        "      image = color_jitter(image)\r\n",
        "      return image\r\n",
        "\r\n",
        "    def crop(self, image, crops):\r\n",
        "      left = int(random.uniform(0, crops['left']))\r\n",
        "      top = int(random.uniform(0, crops['top']))\r\n",
        "      width = int(random.uniform(crops['width'], 224))\r\n",
        "      height = int(random.uniform(crops['height'], 224))\r\n",
        "\r\n",
        "      image = tf.crop(image, top, left, height, width)\r\n",
        "\r\n",
        "      img_shape = np.array(image).shape\r\n",
        "      return image\r\n",
        "\r\n",
        "    def __call__(self, image):\r\n",
        "      image = Image.fromarray(image)\r\n",
        "\r\n",
        "      image = self.resize(image, (224, 224))\r\n",
        "      if self.train:\r\n",
        "        image = self.crop(image, {'left': 15,\r\n",
        "                                  'top': 15,\r\n",
        "                                  'width': 210,\r\n",
        "                                  'height': 210\r\n",
        "                                  })\r\n",
        "        image = self.resize(image, (224, 224))\r\n",
        "        image = self.color_jitter(image)\r\n",
        "        image = self.rotate(image, angle=10)\r\n",
        "\r\n",
        "      image = tf.to_tensor(image)\r\n",
        "      image = tf.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "      return image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjCPu2QlIvgP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYL4HHppItvT"
      },
      "source": [
        "class BeeWaspDataset(Dataset):\r\n",
        "  def __init__(self, image_dir: str = None, dataframe: pd.DataFrame = None, train: bool = False,\r\n",
        "               transforms: Transforms = None):\r\n",
        "    self.image_dir = image_dir\r\n",
        "    self.dataframe = dataframe\r\n",
        "    self.train = train\r\n",
        "    self.transforms = transforms\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    image_path = os.path.join(self.image_dir, self.dataframe.iloc[index][\"path\"])\r\n",
        "    image = cv2.imread(image_path)\r\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
        "    \r\n",
        "    if self.transforms:\r\n",
        "      image = self.transforms(image)\r\n",
        "    \r\n",
        "    if self.train:\r\n",
        "      label = self.dataframe.iloc[index][\"label\"]\r\n",
        "      return image, label\r\n",
        "    else: \r\n",
        "      return image\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "      return len(self.dataframe)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEgS5Oa7I4nA"
      },
      "source": [
        "## Przygotowanie datasetów do treningu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0m3be1rFplQ"
      },
      "source": [
        "train_data = BeeWaspDataset(dataframe=train_df,\r\n",
        "                            image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                            train=True,\r\n",
        "                            transforms=Transforms(train=True))\r\n",
        "\r\n",
        "val_data = BeeWaspDataset(dataframe=val_df,\r\n",
        "                          image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                          train=True,\r\n",
        "                          transforms=Transforms(train=True))\r\n",
        "\r\n",
        "test_data = BeeWaspDataset(dataframe=test_df,\r\n",
        "                          image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                          train=True,\r\n",
        "                          transforms=Transforms(train=False))\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=32, num_workers=4)\r\n",
        "val_loader = DataLoader(dataset=val_data, shuffle=True, batch_size=32, num_workers=4)\r\n",
        "test_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=32, num_workers=4)\r\n",
        "\r\n",
        "dataloaders = {\r\n",
        "    'train': train_loader,\r\n",
        "    'val': val_loader\r\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf-Y67O3AS90"
      },
      "source": [
        "## Model sieci Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pHtwYZ9ASbL"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, in_planes, planes, stride=1):\r\n",
        "        super(BasicBlock, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(\r\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\r\n",
        "                               stride=1, padding=1, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\r\n",
        "                          kernel_size=1, stride=stride, bias=False),\r\n",
        "                nn.BatchNorm2d(self.expansion*planes)\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = self.bn2(self.conv2(out))\r\n",
        "        out += self.shortcut(x)\r\n",
        "        out = F.relu(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "    expansion = 4\r\n",
        "\r\n",
        "    def __init__(self, in_planes, planes, stride=1):\r\n",
        "        super(Bottleneck, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\r\n",
        "                               stride=stride, padding=1, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\r\n",
        "                               planes, kernel_size=1, bias=False)\r\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\r\n",
        "\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\r\n",
        "                          kernel_size=1, stride=stride, bias=False),\r\n",
        "                nn.BatchNorm2d(self.expansion*planes)\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\r\n",
        "        out = self.bn3(self.conv3(out))\r\n",
        "        out += self.shortcut(x)\r\n",
        "        out = F.relu(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "    def __init__(self, block, num_blocks, num_classes=4):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        self.in_planes = 64\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\r\n",
        "                               stride=1, padding=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(64)\r\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\r\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\r\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\r\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\r\n",
        "        self.linear = nn.Linear(512*16*block.expansion, num_classes)\r\n",
        "\r\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\r\n",
        "        strides = [stride] + [1]*(num_blocks-1)\r\n",
        "        layers = []\r\n",
        "        for stride in strides:\r\n",
        "            layers.append(block(self.in_planes, planes, stride))\r\n",
        "            self.in_planes = planes * block.expansion\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = self.layer1(out)\r\n",
        "        out = self.layer2(out)\r\n",
        "        out = self.layer3(out)\r\n",
        "        out = self.layer4(out)\r\n",
        "        out = F.adaptive_avg_pool2d(out, 4)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = self.linear(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "def ResNet18():\r\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\r\n",
        "\r\n",
        "\r\n",
        "def ResNet34():\r\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\r\n",
        "\r\n",
        "\r\n",
        "def ResNet50():\r\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\r\n",
        "\r\n",
        "\r\n",
        "def ResNet101():\r\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\r\n",
        "\r\n",
        "\r\n",
        "def ResNet152():\r\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\r\n",
        "\r\n",
        "\r\n",
        "# model = ResNet50()\r\n",
        "# summary(batch_size=32, input_size=(3, 224, 224), model=model)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrjIwBk6R2UI"
      },
      "source": [
        "## Wytrenowany model z bilbiotek pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1QIFvlgKkaK"
      },
      "source": [
        "from torchsummary import summary\r\n",
        "from torchvision import transforms, models\r\n",
        "\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.model = models.resnet50(pretrained=False)\r\n",
        "        self.model.fc = nn.Linear(512*4, 4)\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        output = self.model(x)\r\n",
        "        return output\r\n",
        "\r\n",
        "# model = Net()\r\n",
        "# summary(batch_size=32, input_size=(3, 224, 224), model=model)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtyM0lTT_L3k"
      },
      "source": [
        "## Skrypt trenujący"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0GOnnFRlYNy"
      },
      "source": [
        "import time\r\n",
        "import copy\r\n",
        "import gc \r\n",
        "\r\n",
        "\r\n",
        "gc.collect()\r\n",
        "\r\n",
        "def train(model, optimizer, scheduler, num_epochs, criterion, device):\r\n",
        "  since = time.time()\r\n",
        "\r\n",
        "  val_acc_history = []\r\n",
        "\r\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "  best_acc = 0.0\r\n",
        "  \r\n",
        "  for epoch in range(num_epochs):\r\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
        "    print('-' * 10) \r\n",
        "\r\n",
        "    # Each epoch has a training and validation phase\r\n",
        "    for phase in ['train', 'val']:\r\n",
        "      if phase == 'train':\r\n",
        "        model.train()\r\n",
        "      else:\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "      running_loss = 0.0\r\n",
        "      running_corrects = 0\r\n",
        "\r\n",
        "      # Iterate over data.\r\n",
        "      for inputs, labels in dataloaders[phase]:\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # forward\r\n",
        "        # track history if only in train\r\n",
        "        with torch.set_grad_enabled(phase == 'train'):\r\n",
        "            outputs = model(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "            _, preds = torch.max(outputs, 1)\r\n",
        "            # backward + optimize only if in training phase\r\n",
        "            if phase == 'train':\r\n",
        "                loss.backward()\r\n",
        "                optimizer.step()\r\n",
        "            \r\n",
        "        # statistics\r\n",
        "        running_loss += loss.detach().item() * inputs.size(0)\r\n",
        "        running_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "      if phase == 'train':\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "      epoch_loss = running_loss / len(dataloaders[phase].dataset)\r\n",
        "      epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\r\n",
        "\r\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "      # deep copy the model\r\n",
        "      if phase == 'val' and epoch_acc > best_acc:\r\n",
        "        best_acc = epoch_acc\r\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "        torch.save(model.state_dict(), \"/content/kaggle_bee_vs_wasp/checkpoint.pth\")\r\n",
        "      if phase == 'val':\r\n",
        "        val_acc_history.append(epoch_acc)\r\n",
        "\r\n",
        "    print()\r\n",
        "\r\n",
        "  time_elapsed = time.time() - since\r\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\r\n",
        "\r\n",
        "  # load best model weights\r\n",
        "  model.load_state_dict(best_model_wts)\r\n",
        "  return model, val_acc_history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WrmL8UQU_KZf",
        "outputId": "f23c1fa6-89b1-463d-8f83-a304f51416ee"
      },
      "source": [
        "from torch.optim import lr_scheduler\r\n",
        "\r\n",
        "\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "print(use_cuda)\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "net = Net()\r\n",
        "net.to(device)\r\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "model, val_acc_history = train(net, optimizer, exp_lr_scheduler, 100, criterion, device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 1.3174 Acc: 0.4485\n",
            "val Loss: 1.2891 Acc: 0.5311\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 1.1753 Acc: 0.5290\n",
            "val Loss: 2.0475 Acc: 0.5119\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 1.1348 Acc: 0.5530\n",
            "val Loss: 1.1676 Acc: 0.5521\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 1.0821 Acc: 0.5727\n",
            "val Loss: 0.9612 Acc: 0.6259\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 1.0244 Acc: 0.5862\n",
            "val Loss: 1.1276 Acc: 0.5678\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 1.0155 Acc: 0.5949\n",
            "val Loss: 0.9841 Acc: 0.6137\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 1.0006 Acc: 0.5974\n",
            "val Loss: 0.8715 Acc: 0.6498\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 0.9021 Acc: 0.6331\n",
            "val Loss: 0.8977 Acc: 0.6434\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 0.8878 Acc: 0.6357\n",
            "val Loss: 0.9786 Acc: 0.6283\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 0.8808 Acc: 0.6419\n",
            "val Loss: 0.8424 Acc: 0.6574\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 0.8674 Acc: 0.6457\n",
            "val Loss: 0.8905 Acc: 0.6399\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.8754 Acc: 0.6343\n",
            "val Loss: 0.8463 Acc: 0.6527\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.8680 Acc: 0.6433\n",
            "val Loss: 0.8376 Acc: 0.6672\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.8615 Acc: 0.6469\n",
            "val Loss: 0.8717 Acc: 0.6451\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.8534 Acc: 0.6515\n",
            "val Loss: 0.8462 Acc: 0.6603\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.8533 Acc: 0.6479\n",
            "val Loss: 0.8468 Acc: 0.6638\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.8503 Acc: 0.6487\n",
            "val Loss: 0.8417 Acc: 0.6562\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.8521 Acc: 0.6468\n",
            "val Loss: 0.8341 Acc: 0.6632\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.8452 Acc: 0.6563\n",
            "val Loss: 0.8458 Acc: 0.6696\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.8449 Acc: 0.6450\n",
            "val Loss: 0.8491 Acc: 0.6521\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.8466 Acc: 0.6526\n",
            "val Loss: 0.8339 Acc: 0.6731\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.8608 Acc: 0.6435\n",
            "val Loss: 0.8432 Acc: 0.6574\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.8396 Acc: 0.6502\n",
            "val Loss: 0.8564 Acc: 0.6440\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.8440 Acc: 0.6541\n",
            "val Loss: 0.8263 Acc: 0.6702\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.8549 Acc: 0.6453\n",
            "val Loss: 0.8683 Acc: 0.6597\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.8495 Acc: 0.6529\n",
            "val Loss: 0.8359 Acc: 0.6574\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.8479 Acc: 0.6511\n",
            "val Loss: 0.8355 Acc: 0.6481\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.8526 Acc: 0.6484\n",
            "val Loss: 0.8275 Acc: 0.6550\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.8467 Acc: 0.6525\n",
            "val Loss: 0.8313 Acc: 0.6597\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.8479 Acc: 0.6486\n",
            "val Loss: 0.8193 Acc: 0.6649\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.8536 Acc: 0.6506\n",
            "val Loss: 0.8292 Acc: 0.6591\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.8421 Acc: 0.6542\n",
            "val Loss: 0.8327 Acc: 0.6608\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.8485 Acc: 0.6478\n",
            "val Loss: 0.8374 Acc: 0.6649\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.8508 Acc: 0.6439\n",
            "val Loss: 0.8455 Acc: 0.6655\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.8511 Acc: 0.6535\n",
            "val Loss: 0.8359 Acc: 0.6597\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.8537 Acc: 0.6487\n",
            "val Loss: 0.8524 Acc: 0.6451\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.8508 Acc: 0.6476\n",
            "val Loss: 0.8178 Acc: 0.6672\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.8447 Acc: 0.6575\n",
            "val Loss: 0.8399 Acc: 0.6527\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.8486 Acc: 0.6505\n",
            "val Loss: 0.8580 Acc: 0.6568\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.8391 Acc: 0.6539\n",
            "val Loss: 0.8346 Acc: 0.6638\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.8427 Acc: 0.6542\n",
            "val Loss: 0.8367 Acc: 0.6608\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.8488 Acc: 0.6537\n",
            "val Loss: 0.8298 Acc: 0.6643\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.8477 Acc: 0.6523\n",
            "val Loss: 0.8524 Acc: 0.6504\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.8457 Acc: 0.6477\n",
            "val Loss: 0.8491 Acc: 0.6446\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.8454 Acc: 0.6468\n",
            "val Loss: 0.8408 Acc: 0.6707\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.8548 Acc: 0.6550\n",
            "val Loss: 0.8360 Acc: 0.6579\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.8474 Acc: 0.6510\n",
            "val Loss: 0.8476 Acc: 0.6545\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.8481 Acc: 0.6469\n",
            "val Loss: 0.8258 Acc: 0.6643\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.8536 Acc: 0.6498\n",
            "val Loss: 0.8237 Acc: 0.6585\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.8445 Acc: 0.6549\n",
            "val Loss: 0.8202 Acc: 0.6556\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n",
            "train Loss: 0.8513 Acc: 0.6440\n",
            "val Loss: 0.8193 Acc: 0.6655\n",
            "\n",
            "Epoch 51/99\n",
            "----------\n",
            "train Loss: 0.8478 Acc: 0.6518\n",
            "val Loss: 0.8485 Acc: 0.6475\n",
            "\n",
            "Epoch 52/99\n",
            "----------\n",
            "train Loss: 0.8472 Acc: 0.6502\n",
            "val Loss: 0.8442 Acc: 0.6556\n",
            "\n",
            "Epoch 53/99\n",
            "----------\n",
            "train Loss: 0.8549 Acc: 0.6443\n",
            "val Loss: 0.8564 Acc: 0.6515\n",
            "\n",
            "Epoch 54/99\n",
            "----------\n",
            "train Loss: 0.8528 Acc: 0.6452\n",
            "val Loss: 0.8593 Acc: 0.6591\n",
            "\n",
            "Epoch 55/99\n",
            "----------\n",
            "train Loss: 0.8539 Acc: 0.6498\n",
            "val Loss: 0.8289 Acc: 0.6684\n",
            "\n",
            "Epoch 56/99\n",
            "----------\n",
            "train Loss: 0.8578 Acc: 0.6482\n",
            "val Loss: 0.8362 Acc: 0.6684\n",
            "\n",
            "Epoch 57/99\n",
            "----------\n",
            "train Loss: 0.8406 Acc: 0.6532\n",
            "val Loss: 0.8440 Acc: 0.6638\n",
            "\n",
            "Epoch 58/99\n",
            "----------\n",
            "train Loss: 0.8505 Acc: 0.6496\n",
            "val Loss: 0.8234 Acc: 0.6638\n",
            "\n",
            "Epoch 59/99\n",
            "----------\n",
            "train Loss: 0.8473 Acc: 0.6516\n",
            "val Loss: 0.8674 Acc: 0.6463\n",
            "\n",
            "Epoch 60/99\n",
            "----------\n",
            "train Loss: 0.8502 Acc: 0.6479\n",
            "val Loss: 0.8287 Acc: 0.6702\n",
            "\n",
            "Epoch 61/99\n",
            "----------\n",
            "train Loss: 0.8515 Acc: 0.6491\n",
            "val Loss: 0.8406 Acc: 0.6597\n",
            "\n",
            "Epoch 62/99\n",
            "----------\n",
            "train Loss: 0.8508 Acc: 0.6466\n",
            "val Loss: 0.8467 Acc: 0.6620\n",
            "\n",
            "Epoch 63/99\n",
            "----------\n",
            "train Loss: 0.8501 Acc: 0.6488\n",
            "val Loss: 0.8489 Acc: 0.6498\n",
            "\n",
            "Epoch 64/99\n",
            "----------\n",
            "train Loss: 0.8467 Acc: 0.6501\n",
            "val Loss: 0.8529 Acc: 0.6568\n",
            "\n",
            "Epoch 65/99\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1a307d94d391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-5d437e56e5c1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, num_epochs, criterion, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm1G5OOwZrPJ"
      },
      "source": [
        "# Podsumowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myTvEL6BZtYq",
        "outputId": "4b1bf0a2-d000-42c1-a643-f14d2ccbe238"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "model_ft = Net()\r\n",
        "model_ft.load_state_dict(torch.load(\"/content/kaggle_bee_vs_wasp/checkpoint.pth\"))\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "print(use_cuda)\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "model_ft.cuda()\r\n",
        "model_ft.eval()\r\n",
        "\r\n",
        "nb_classes = 4\r\n",
        "\r\n",
        "# Initialize the prediction and label lists(tensors)\r\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\r\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    for i, (inputs, classes) in enumerate(dataloaders['val']):\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        classes = classes.to(device)\r\n",
        "        outputs = model_ft(inputs)\r\n",
        "        _, preds = torch.max(outputs, 1)\r\n",
        "\r\n",
        "        # Append batch prediction results\r\n",
        "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\r\n",
        "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\r\n",
        "\r\n",
        "# Confusion matrix\r\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\r\n",
        "print(conf_mat)\r\n",
        "\r\n",
        "# Per-class accuracy\r\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\r\n",
        "print(class_accuracy)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "[[301  64   6 113]\n",
            " [ 20 199   3 135]\n",
            " [ 19   2  15  92]\n",
            " [ 50  73  16 611]]\n",
            "[62.19008264 55.74229692 11.71875    81.46666667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "flqNhMJWghOI",
        "outputId": "95249a61-744a-4cbf-93a2-a05f9bb749c1"
      },
      "source": [
        "import seaborn as sn\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "df_cm = pd.DataFrame(conf_mat, index = [i for i in ['bee', 'wasp', 'insect', 'other']],\r\n",
        "                  columns = [i for i in ['bee', 'wasp', 'insect', 'other']])\r\n",
        "plt.figure(figsize = (10,7))\r\n",
        "sn.heatmap(df_cm, annot=True, fmt=\"d\")\r\n",
        "\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0961309470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}