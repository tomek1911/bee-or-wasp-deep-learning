{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bee-vs-wasp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "cMHQoPY4O_dS",
        "outputId": "0bc66f6d-a82c-4dba-b709-262f79688b60"
      },
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# import your kaggle credentials in kaggle.json file sa explained in:\n",
        "# https://www.kaggle.com/general/74235\n",
        "files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-088b03b9-d67b-4456-ba3b-85c700500f19\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-088b03b9-d67b-4456-ba3b-85c700500f19\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"micharosa\",\"key\":\"c34f6df8dda23f417041431ae70e46c8\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFkX76XoQiF1",
        "outputId": "1700daa3-ffbe-4e09-b631-c5936ad4467a"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# check if kaggle API works\n",
        "! kaggle datasets list"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                            title                                                size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "utkarshxy/who-worldhealth-statistics-2020-complete             World Health 2020 üåè | For Geospatial Analysis         1MB  2021-01-06 16:22:50            859  \n",
            "gpreda/pfizer-vaccine-tweets                                   Pfizer Vaccine Tweets                               403KB  2021-01-06 15:11:07            607  \n",
            "google/android-smartphones-high-accuracy-datasets              Android smartphones high accuracy GNSS datasets       1GB  2020-12-23 01:51:11            127  \n",
            "ashkhagan/women-representation-in-city-property-sanfrancisco   Women Representation in City Property SanFrancisco    3KB  2020-12-13 05:18:14            131  \n",
            "arashnic/covid19-case-surveillance-public-use-dataset          Covid-19 Case Surveillance Public Use Dataset        46MB  2020-12-21 02:24:21            435  \n",
            "arashnic/mind-news-dataset                                     MIND: Microsoft News Recommendation Dataset          51MB  2020-12-21 00:22:50             57  \n",
            "rowhitswami/all-indian-companies-registration-data-1900-2019   Indian Companies Registration Data [1857 - 2020]    112MB  2020-12-12 03:59:01            162  \n",
            "sakshigoyal7/credit-card-customers                             Credit Card customers                               379KB  2020-11-19 07:38:44          14211  \n",
            "arashnic/hr-analytics-job-change-of-data-scientists            HR Analytics: Job Change of Data Scientists         295KB  2020-12-07 00:25:10           2590  \n",
            "shashwatwork/impact-of-covid19-pandemic-on-the-global-economy  Impact of Covid-19 Pandemic on the Global Economy     1MB  2020-11-29 14:16:30           1565  \n",
            "alexgude/california-traffic-collision-data-from-switrs         California Traffic Collision Data from SWITRS         1GB  2020-11-22 16:51:55           2267  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019          Amazon Top 50 Bestselling Books 2009 - 2019          15KB  2020-10-13 09:39:21          11512  \n",
            "mrmorj/dataset-of-songs-in-spotify                             Dataset of songs in Spotify                           3MB  2020-12-06 09:46:55           1046  \n",
            "yamaerenay/spotify-dataset-19212020-160k-tracks                Spotify Dataset 1921-2020, 160k+ Tracks              16MB  2020-11-25 21:14:12          13958  \n",
            "szymonjanowski/internet-articles-data-with-users-engagement    Internet news data with readers engagement            3MB  2020-11-21 17:09:57           3637  \n",
            "babyoda/women-entrepreneurship-and-labor-force                 Women Entrepreneurship and Labor Force                1KB  2020-11-21 08:38:51           5387  \n",
            "google/tinyquickdraw                                           QuickDraw Sketches                                   11GB  2018-04-18 19:38:04           2687  \n",
            "datasnaek/youtube-new                                          Trending YouTube Video Statistics                   201MB  2019-06-03 00:56:47         122658  \n",
            "zynicide/wine-reviews                                          Wine Reviews                                         51MB  2017-11-27 17:08:04         124619  \n",
            "datasnaek/chess                                                Chess Game Dataset (Lichess)                          3MB  2017-09-04 03:09:09          13121  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-GPY6GAQ8bA",
        "outputId": "942f4a05-b250-47a0-c59b-12903f69f291"
      },
      "source": [
        "! kaggle datasets download jerzydziewierz/bee-vs-wasp --unzip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading bee-vs-wasp.zip to /content\n",
            " 98% 546M/559M [00:03<00:00, 174MB/s]\n",
            "100% 559M/559M [00:03<00:00, 159MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTkg44dFB6a0"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import imgaug as ia\r\n",
        "import imgaug.augmenters as iaa\r\n",
        "import imgaug.parameters as iap\r\n",
        "from imgaug.augmenters import Sequential\r\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import torchvision.transforms.functional as tf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP99k0HnN-6L"
      },
      "source": [
        "## Wczytanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8owr7qN9lV",
        "outputId": "1ecd0c1e-5317-4524-e02a-fae93acfd39b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = pd.read_csv(\"/content/kaggle_bee_vs_wasp/labels.csv\")\r\n",
        "for i in data.index:\r\n",
        "    data[\"path\"].iloc[i] = data[\"path\"].iloc[i].replace(\"\\\\\", \"/\")\r\n",
        "le = LabelEncoder()\r\n",
        "le.fit(data[\"label\"])\r\n",
        "data[\"label\"] = le.transform(data[\"label\"])\r\n",
        "data.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11421 entries, 0 to 11420\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   id                   11421 non-null  int64 \n",
            " 1   path                 11421 non-null  object\n",
            " 2   is_bee               11421 non-null  int64 \n",
            " 3   is_wasp              11421 non-null  int64 \n",
            " 4   is_otherinsect       11421 non-null  int64 \n",
            " 5   is_other             11421 non-null  int64 \n",
            " 6   photo_quality        11421 non-null  int64 \n",
            " 7   is_validation        11421 non-null  int64 \n",
            " 8   is_final_validation  11421 non-null  int64 \n",
            " 9   label                11421 non-null  int64 \n",
            "dtypes: int64(9), object(1)\n",
            "memory usage: 892.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HxqqrG0TR_1"
      },
      "source": [
        "## Podzia≈Ç danych "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqT-eVrKTX2q",
        "outputId": "b37b2e9e-07cd-422f-a275-f6d6e51ad330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def split_data(dataset):\r\n",
        "    index = list()\r\n",
        "    validation = pd.DataFrame()\r\n",
        "    final_validation = pd.DataFrame()\r\n",
        "    for i in data.index:\r\n",
        "        if dataset[\"is_validation\"].iloc[i] == 1:\r\n",
        "            validation = validation.append(dataset.iloc[i])\r\n",
        "            index.append(i)\r\n",
        "        if dataset[\"is_final_validation\"].iloc[i] == 1:    \r\n",
        "            final_validation = final_validation.append(dataset.iloc[i])\r\n",
        "            index.append(i)\r\n",
        "\r\n",
        "    dataset = dataset.drop(dataset.index[index])\r\n",
        "    dataset = dataset.reset_index()\r\n",
        "    validation = validation.reset_index()\r\n",
        "    final_validation = final_validation.reset_index()\r\n",
        "    return dataset, validation, final_validation \r\n",
        "\r\n",
        "train_df, val_df, test_df = split_data(data)\r\n",
        "\r\n",
        "# sanity check\r\n",
        "print(\"Length of train dataset: \", len(train_df))\r\n",
        "print(\"Length of validation dataset: \" ,len(val_df))\r\n",
        "print(\"Length of test dataset: \", len(test_df))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train dataset:  7939\n",
            "Length of validation dataset:  1719\n",
            "Length of test dataset:  1763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDAj2Y30V40p"
      },
      "source": [
        "## Augmentacja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4iNPz59V3Wa"
      },
      "source": [
        "class Transforms():\r\n",
        "    def __init__(self, train: bool = False):\r\n",
        "      self.train = train\r\n",
        "    \r\n",
        "    def rotate(self, image, angle):\r\n",
        "      angle = random.uniform(-angle, +angle)\r\n",
        "\r\n",
        "      transformation_matrix = torch.tensor([\r\n",
        "          [+cos(radians(angle)), -sin(radians(angle))], \r\n",
        "          [+sin(radians(angle)), +cos(radians(angle))]\r\n",
        "      ])\r\n",
        "\r\n",
        "      image = imutils.rotate(np.array(image), angle)\r\n",
        "\r\n",
        "      return Image.fromarray(image)\r\n",
        "\r\n",
        "    def resize(self, image, img_size):\r\n",
        "      image = tf.resize(image, img_size)\r\n",
        "      return image\r\n",
        "\r\n",
        "    def color_jitter(self, image, landmarks):\r\n",
        "      color_jitter = transforms.ColorJitter(brightness=0.3, \r\n",
        "                                            contrast=0.3,\r\n",
        "                                            saturation=0.3, \r\n",
        "                                            hue=0.1)\r\n",
        "      image = color_jitter(image)\r\n",
        "      return image\r\n",
        "\r\n",
        "    def crop(self, image, crops):\r\n",
        "      left = int(crops['left'])\r\n",
        "      top = int(crops['top'])\r\n",
        "      width = int(crops['width'])\r\n",
        "      height = int(crops['height'])\r\n",
        "\r\n",
        "      image = tf.crop(image, top, left, height, width)\r\n",
        "\r\n",
        "      img_shape = np.array(image).shape\r\n",
        "      return image\r\n",
        "\r\n",
        "    def __call__(self, image, crops):\r\n",
        "      image = Image.fromarray(image)\r\n",
        "      \r\n",
        "      image = self.resize(image,  (224, 224))\r\n",
        "      if self.train:\r\n",
        "        image = self.crop(image, crops)\r\n",
        "        image = self.resize(image,  (224, 224))\r\n",
        "        image = self.color_jitter(image)\r\n",
        "        image = self.rotate(image, angle=10)\r\n",
        "\r\n",
        "      image = tf.to_tensor(image)\r\n",
        "      image = tf.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "      return image"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjCPu2QlIvgP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYL4HHppItvT"
      },
      "source": [
        "class BeeWaspDataset(Dataset):\r\n",
        "  def __init__(self, image_dir: str = None, dataframe: pd.DataFrame = None, train: bool = False,\r\n",
        "               transforms: Transforms = None):\r\n",
        "    self.image_dir = image_dir\r\n",
        "    self.dataframe = dataframe\r\n",
        "    self.train = train\r\n",
        "    self.transforms = transforms\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    image_path = os.path.join(self.image_dir, self.dataframe.iloc[index][\"path\"])\r\n",
        "    image = cv2.imread(image_path)\r\n",
        "    \r\n",
        "    if self.transform:\r\n",
        "      image = self.transform(image)\r\n",
        "    \r\n",
        "    if self.train:\r\n",
        "      label = self.dataframe.iloc[index][\"label\"]\r\n",
        "      return image, label\r\n",
        "    else: \r\n",
        "      return image\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "      return len(self.dataframe)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEgS5Oa7I4nA"
      },
      "source": [
        "## Przygotowanie dataset√≥w do treningu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0m3be1rFplQ"
      },
      "source": [
        "train_data = BeeWaspDataset(dataframe=train_df,\r\n",
        "                            image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                            train=True,\r\n",
        "                            transforms=Transforms(train=True))\r\n",
        "\r\n",
        "val_data = BeeWaspDataset(dataframe=val_df,\r\n",
        "                          image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                          train=True,\r\n",
        "                          transforms=Transforms(train=False))\r\n",
        "\r\n",
        "test_data = BeeWaspDataset(dataframe=test_df,\r\n",
        "                          image_dir=\"/content/kaggle_bee_vs_wasp/\",\r\n",
        "                          train=True,\r\n",
        "                          transforms=Transforms(train=False))\r\n",
        "\r\n",
        "train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=32, num_workers=4)\r\n",
        "val_loader = DataLoader(dataset=val_data, shuffle=True, batch_size=32, num_workers=4)\r\n",
        "test_loader = DataLoader(dataset=test_data, shuffle=True, batch_size=32, num_workers=4)"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}